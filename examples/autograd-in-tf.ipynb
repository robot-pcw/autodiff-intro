{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autodiff in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=x^2, dy/dx=2x=6.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tensorflow中使用tf.GradientTape开启上下文管理器，并对Operations进行'监控'，用于自动微分。\n",
    "Trainable variables：会被自动监控;\n",
    "Tensors：需要手动监控，通过调用该上下文管理器的`watch` method;\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "# normal Tensor\n",
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = x * x\n",
    "    dy_dx = g.gradient(y, x)\n",
    "    print(f\"y=x^2, dy/dx=2x={dy_dx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dw=75.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(5.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = w ** 3 \n",
    "    dz_dw = tape.gradient(z, w)\n",
    "    print(f\"dz/dw={dz_dw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx=2x=10.0\n",
      "d2y/dx2=2.0\n"
     ]
    }
   ],
   "source": [
    " \"\"\"支持高阶导\"\"\"\n",
    "x = tf.Variable(5.0)\n",
    "with tf.GradientTape() as g:\n",
    "    with tf.GradientTape() as gg:\n",
    "        gg.watch(x)\n",
    "        y = x * x\n",
    "        dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
    "        print(f\"dy/dx=2x={dy_dx}\")\n",
    "    d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
    "    print(f\"d2y/dx2={d2y_dx2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient in nn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5.]\n",
      " [10.]], shape=(2, 1), dtype=float32)\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "dy/dw=w^T=[[3.]\n",
      " [3.]]\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "dy/dx=[[2. 3.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\"\"\"dense layer\"\"\"\n",
    "x = tf.Variable([[1.0, 1.0], [2.0, 2.0]])\n",
    "w = tf.Variable([[2.0,], [3.0,]])\n",
    "with tf.GradientTape(persistent = True) as tape:\n",
    "    y = tf.matmul(x, w)\n",
    "    print(y)\n",
    "    dy_dw = tape.gradient(y, w)\n",
    "    print(f\"dy/dw={dy_dw}\")\n",
    "    dy_dx = tape.gradient(y, x)\n",
    "    print(f\"dy/dx={dy_dx}\")\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1.]\n",
      "   [2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[4.]\n",
      "   [5.]\n",
      "   [6.]]\n",
      "\n",
      "  [[7.]\n",
      "   [8.]\n",
      "   [9.]]]], shape=(1, 3, 3, 1), dtype=float32)\n",
      "dy/dw=[[3.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1., 2., 3.],[4., 5., 6.],[7., 8., 9.]])\n",
    "x = tf.reshape(x, [1, 3, 3, 1])\n",
    "max_pool_2d = layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid')\n",
    "max_pool_2d.build(input_shape=(1, 3, 3, 1))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(max_pool_2d.variables)\n",
    "    y = max_pool_2d(x)\n",
    "    print(x)\n",
    "    dy_dx = tape.gradient(y, max_pool_2d.variables)\n",
    "    print(f\"dy/dw={dy_dw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
